name: Generate Website

permissions:
  contents: write    # Enables read/write access to repository contents
  issues: write      # Grants permission to manage issues (if needed)
  pull-requests: write # Allows you to update pull requests

on:
  repository_dispatch:
    types: [website-generation]  # Match this with your route.js event type

jobs:
  generate-website:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9' # Ensure this matches version used by webhook_handler if relevant

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install boto3 requests jinja2 python-dotenv xmltodict flask

      - name: Create directories # Ensure directories needed by the script exist
        run: |
          mkdir -p clients
          mkdir -p python-service/templates # Create dir where webhook_handler expects templates

      - name: Copy templates for Action context # Make templates accessible to inline script
        run: |
          # Copy templates from the python-service dir to a place the inline script's
          # default FileSystemLoader('.') can find them easily.
          # If your webhook_handler.py's FileSystemLoader points elsewhere, adjust accordingly.
          cp python-service/templates/business.html templates/business.html
          # Optional: Copy default template if it exists
          if [ -f python-service/templates/default.html ]; then cp python-service/templates/default.html templates/default.html; fi
          # Optional: Copy styles.css if it's pre-built and stored here
          if [ -f python-service/templates/styles.css ]; then cp python-service/templates/styles.css templates/styles.css; fi


      - name: Process website content
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_PAGES_TARGET: clickcatalyst-digital.github.io # Default or from env
        run: |
          python -c "
          import json, sys, os, shutil
          import logging
          from pathlib import Path # Moved import to top

          # Configure logging
          logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(name)s - %(message)s')
          logger = logging.getLogger(__name__)

          # Append path and import necessary functions AFTER basic setup
          sys.path.append('./python-service')
          try:
              # Assuming these functions handle their own boto3/jinja setup or use global vars
              from webhook_handler import download_from_s3, extract_content_json, download_assets, render_template
          except ImportError as import_err:
              logger.error(f'Failed to import from webhook_handler: {import_err}')
              sys.exit(1)
          except Exception as setup_err:
              logger.error(f'Error during setup/import from webhook_handler: {setup_err}')
              sys.exit(1)


          # Get the GitHub event data
          event_path = os.environ.get('GITHUB_EVENT_PATH')
          if not event_path or not os.path.exists(event_path):
              logger.error('GITHUB_EVENT_PATH not found or invalid.')
              sys.exit(1)
          try:
              with open(event_path) as f:
                  event_data = json.load(f)
          except Exception as json_err:
              logger.error(f'Failed to load GITHUB_EVENT_PATH JSON: {json_err}')
              sys.exit(1)

          # Extract data from payload
          payload = event_data.get('client_payload', {})
          bucket = payload.get('bucket')
          folder_name = payload.get('folderName')
          website_id = payload.get('websiteId')
          website_type = payload.get('websiteType', 'business') # Default to business

          if not all([bucket, folder_name, website_id]):
              logger.error('Missing bucket, folderName, or websiteId in payload')
              sys.exit(1)

          logger.info(f'Processing website: {website_id} ({folder_name}) of type {website_type}')

          # Main processing block
          try:
              # --- Download content.json (with improved error handling) ---
              content_bytes = None
              content_key_plain = f'{folder_name}/content.json'
              content_key_gz = f'{folder_name}/content.json.gz'

              content_bytes = download_from_s3(bucket, content_key_plain)
              if not content_bytes:
                  logger.info(f'{content_key_plain} not found, trying {content_key_gz}')
                  content_bytes = download_from_s3(bucket, content_key_gz)

              if not content_bytes:
                  logger.error(f'Failed to download content file ({content_key_plain} or {content_key_gz})')
                  sys.exit(1)

              content_data = extract_content_json(content_bytes)
              if not content_data:
                  logger.error('Failed to extract content.json data')
                  sys.exit(1)

              # --- Create output directory ---
              client_dir = Path(f'clients/{folder_name}')
              client_dir.mkdir(exist_ok=True, parents=True)

              # --- Save raw content.json (for debugging) ---
              try:
                  with open(client_dir / 'content.json', 'w') as f:
                      json.dump(content_data, f, indent=2)
              except Exception as dump_err:
                  logger.warning(f'Could not save raw content.json: {dump_err}')


              # --- Download assets ---
              asset_keys = {
                  'logo': content_data.get('logo'),
                  'banner': content_data.get('banner'),
                  'about_image': content_data.get('about_image')
                  # Add other potential assets if needed by templates
              }
              # Add gallery images dynamically if used by template
              # for i, image_path in enumerate(content_data.get('gallery', [])):
              #     if image_path: asset_keys[f'gallery_{i}'] = image_path

              downloaded_assets = download_assets(bucket, folder_name, asset_keys) # Assumes this uses the imported s3_client

              # --- Render HTML ---
              # Assumes render_template uses the Jinja env from webhook_handler
              html_output = render_template(content_data, downloaded_assets)

              # --- Save HTML ---
              try:
                  with open(client_dir / 'index.html', 'w', encoding='utf-8') as f:
                      f.write(html_output)
                  logger.info(f'Successfully generated index.html for {folder_name}')
              except Exception as write_err:
                  logger.error(f'Failed to write index.html: {write_err}')
                  sys.exit(1)


              # --- Copy Pre-built CSS ---
              # This assumes styles.css was generated *before* this action runs
              # and placed correctly (e.g., by the Copy templates step above)
              prebuilt_css_path = Path('templates/styles.css') # Path relative to checkout root
              target_css_path = client_dir / 'styles.css'

              if prebuilt_css_path.exists():
                  try:
                      shutil.copy2(prebuilt_css_path, target_css_path)
                      # Use str() for Path object in f-string just to be safe
                      logger.info(f'Copied {str(prebuilt_css_path)} to {str(target_css_path)}')
                  except Exception as css_copy_error:
                      logger.error(f'Failed to copy styles.css: {css_copy_error}')
                      # Decide if this failure should stop the deployment
                      # sys.exit(1)
              else:
                  logger.warning(f'Pre-built {str(prebuilt_css_path)} not found. Styling will be missing.')
                  # Decide if this failure should stop the deployment
                  # sys.exit(1)

              print(f'Website content generation successful for {folder_name}')

          # --- Overall Error Handling ---
          except Exception as e:
              logger.exception(f'Error during website content processing: {e}') # Use logger.exception for traceback
              print(f'Website generation failed: {str(e)}')
              sys.exit(1)
          "

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./clients # Deploy the entire clients directory
          # Optional: Specify destination directory in gh-pages branch
          # destination_dir: '.' # Deploy to root of gh-pages
          # Keep history or force push (force push is common for gh-pages)
          force_orphan: true
          # Optional: Add .nojekyll file if needed
          # keep_files: true # Set to true if you have other files in publish_dir you want to keep
          # publish_branch: gh-pages # Default is gh-pages
          # cname: your.custom.domain # Add CNAME if using custom domain via GH Pages settings
